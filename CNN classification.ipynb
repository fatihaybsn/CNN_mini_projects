{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "> ÇALIŞMA YAPARKEN DEFTER KULLANARAK TEKRAR EDELİM YOKSA HAYAL ETMEK ZOR OLUR.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "sCV30xyVhFbE",
        "outputId": "6bdf62d0-ecd7-4ea2-8104-a1f9b137b9e9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # type: ignore  \n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIleuCAjoFD8",
        "outputId": "c1dfa2df-561a-497f-8457-ff2c7052652f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.17.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__ # Tensorflow 2 sürümünü kullanıyoruz. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0koUcJMJpEBD",
        "outputId": "063d5630-372b-4858-dd20-5238578dc5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('training_set',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SH4WzfOhpKc3",
        "outputId": "8e4551f9-89b7-4d16-ac84-d40725ed2481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 16000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('test_set', # Path işlemi\n",
        "                                            target_size = (128, 128), # Foto boyutu aynı\n",
        "                                            batch_size = 32, # aynı\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN (CNN başlatılması)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SAUt4UMPlhLS"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### STEP 1 - Convolution (Konvülasyon aşaması ekliyoruz.) ANN de burada gizli katmanlar eklemiştik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XPzPrMckl-hV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' \\n---------------------------------------------------------------- FİLTERS ------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFilters parametresi, konvolüsyon katmanının kaç tane filtre (Feature Detectör) kullanacağını belirtir. Her filtre, giriş görüntüsündeki özellikleri (örneğin, kenarlar, dokular) yakalayan bir öğrenilebilir parametredir.\\nÖRNEK: Yukarıda 32 olarak verilmiş. Bu, katmanda 32 farklı filtre olduğunu gösterir. Her bir filtre, giriş görüntüsünden farklı özellikler yakalamaya çalışır.\\n    \\nDEĞİŞTİRLME DURUMU: Daha yüksek değer (filters=64, 128, vb.) daha fazla filtre demektir. Bu, daha karmaşık özelliklerin yakalanmasını sağlar, ancak modelin karmaşıklığını ve hesaplama maliyetini artırır. \\nDaha düşük değer (filters=16, 8) hesaplama maliyetini düşürür ancak daha az özellik yakalanır.\\n\\nHESAPLAMA MAALİYETİ NEDİR ? : \\nHesaplama maliyeti, filtre sayısı, filtre boyutu ve giriş boyutuna bağlı olarak değişir. \\nFiltre sayısı arttıkça veya daha büyük giriş verileri ile çalıştıkça, hesaplama süresi ve kaynak gereksinimi de artar. Bu nedenle model tasarımında hesaplama maliyeti ve performans arasında bir denge kurmak önemlidir.\\n\\n\\n---------------------------------------------------------------- KERNEL_SİZE --------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFiltre (Feature Detectör) boyutunu belirler . Yukarıda 3x3 filtre boyutu kullanılmış. Bu, her bir filtrenin 3x3 piksel büyüklüğünde olduğunu gösterir.\\nBu filtre, 3x3 piksellik bir pencere ile giriş verisi üzerinde gezinerek çalışır.\\n\\nDEĞİŞTİRLME DURUMU: Daha küçük kernel boyutu (kernel_size=1) daha az bilgi yakalar, fakat daha düşük hesaplama maliyeti getirir. \\nDaha büyük kernel boyutu (kernel_size=5, 7) daha geniş alanları inceleyebilir, fakat bu daha fazla hesaplama gerektirir.\\n\\n\\n---------------------------------------------------------------- ACTİVATİON ---------------------------------------------------------------------------------------------------------------------------------------------\\n\\nRectified Linear Unit aktivasyon fonksiyonunun kullanılacağı belirtiliyor.Bu fonksiyonun sigmoid softmax gibi tercihlerine yapacağımız projeye göre karar vereceğiz.\\n\\n\\n---------------------------------------------------------------- İNPUT_SHAPE --------------------------------------------------------------------------------------------------------------------------------------------\\n\\nİnput_shape sadece ilk katmanımızı eklediğimizde kullanılır. Yani daha sonra tekrardan bir Convolutional katman eklemek istersek input shape olmadan ekleyeceğiz.\\nTest ve train setini Preprocessing yani ön işleme aşamasında \"target_size = (64, 64)\" olarak belirledik ve bunun fotoğrfların boyutunu belirlediğini söyledik. \\nEğer Renkli fotolarla görüntülerle çalışıyorsak RGB olur yani \"input_shape=[64, 64, 3]\" 64 lerin yanına 3 yazarız ama siyah beyaz gri tonlamasında fotolarla çalışıyorsak 3 yerine 1 yazmalıyız. \"input_shape=[64, 64, 1]\"\\nEğer ki \"target_size = (128, 128)\" olarak belirleseydik ve renkli görüntülerle çalışsaydık \"input_shape=[128, 128, 3]\" yazmamız gerekecekti.\\n\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[128, 128, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### STEP 2 - Pooling  - Bir havuzlama katmanını cnn e bağlıyoruz. konvolüsyon ve Pooling işlemleri ard arda bağlanmış oluyor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ncpqPl69mOac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nCNN\\'imize MaxPooling uygulamak istersek yukarıdaki satırı Copy-Paste yapabiliriz. \\n\\n---------------------------------------------------------------------- POOL_SİZE -----------------------------------------------------------------------------------------------------------\\n\\nBir image\\'e Feature Detectör uygulandıktan sonra elde edilen Feature Map\\'e Max Pooling işlemi uygulanır ve Pooled Feature Map elde edilir bunu biliyoruz. \\nFeature Map\\'e uygulanmak istenen Max Pooling işlemi için belirli boyutlarda bir kare kullanılması gerekiyor.\\nBir image\\'e uygulanan konvülasyon işlemi için gereken Feature Detectör gibi burada da böyle bir kareye ihtiyaç var. \\nFeature Detectör\\'ün boyutlarını belirlemek için kernel_size kullanıyorduk \\nburada da bu karenin boyutunu belirten parametreye pool_size denir. Bu kareye ben pool karesi diyorum.\\n!!! 2 tavsiye edilen pool boyutudur !!!\\n\\n\\n---------------------------------------------------------------------- STRİDES --------------------------------------------------------------------------------------------------------------\\n\\nPooling işlemlerinde bu pool karesini 2 adım kaydırmak mantıklı bir tercihtir bu yüzden genelde 2 tercih edilir. \\nBu kaydırma işlemi \"strides=2\" olarak belirtilir.\\n\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer -- Tekrardan Konvolüsyon katmanı eklemek istiyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i_-FZjn_m8gk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu')) \n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### STEP 3 - Flattening (Düzleştirme) Bu işlemden sonra artık ANN geliştirmenin aynısını yapıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6AZeOGCvnNZn"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### STEP 4 - Full Connection (ANN aynısını yapabilmek için gizli katmanlar ekliyoruz.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8GtmUlLd26Nq"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### STEP 5 - Output Layer (ANN'de olduğu gibi karar verecek son Nöronu ekliyoruz.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1p_Zj1Mc3Ko_"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN (Ağırlıklar ayarlanıyor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NALksrNQpUlJ"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set (Modelimizi Training seti üzerinden eğitiyoruz ve aynı zamanda Test seti üzerinden değerlendiriyoruz.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUj1W4PJptta",
        "outputId": "3e316b23-e699-491c-9d2c-66791f3d851e"
      },
      "outputs": [],
      "source": [
        "history = cnn.fit(x = training_set,    \n",
        "        validation_data = test_set, \n",
        "        epochs = 20)                 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Eğitim sonrası analiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # type: ignore\n",
        "\n",
        "# Model eğitimi sırasında history objesinde kayıt edilen accuracy ve loss değerlerini çizdiriyoruz\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 5))  # Grafik boyutunu belirliyoruz\n",
        "\n",
        "    # Accuracy (doğruluk) grafiği\n",
        "    plt.subplot(1, 2, 1)  # İlk grafiği sol tarafa yerleştiriyoruz\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy', color='b')  # Eğitim doğruluğunu mavi ile çizdiriyoruz\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='r')  # Doğrulama doğruluğunu kırmızı ile çizdiriyoruz\n",
        "    plt.title('Training and Validation Accuracy')  # Grafiğin başlığını ekliyoruz\n",
        "    plt.xlabel('Epoch')  # X eksenine \"Epoch\" yazıyoruz\n",
        "    plt.ylabel('Accuracy')  # Y eksenine \"Accuracy\" yazıyoruz\n",
        "    plt.legend()  # Sağ alt köşeye açıklama ekliyoruz\n",
        "\n",
        "    # Loss (kayıp) grafiği\n",
        "    plt.subplot(1, 2, 2)  # İkinci grafiği sağ tarafa yerleştiriyoruz\n",
        "    plt.plot(history.history['loss'], label='Training Loss', color='b')  # Eğitim kaybını mavi ile çizdiriyoruz\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', color='r')  # Doğrulama kaybını kırmızı ile çizdiriyoruz\n",
        "    plt.title('Training and Validation Loss')  # Grafiğin başlığını ekliyoruz\n",
        "    plt.xlabel('Epoch')  # X eksenine \"Epoch\" yazıyoruz\n",
        "    plt.ylabel('Loss')  # Y eksenine \"Loss\" yazıyoruz\n",
        "    plt.legend()  # Sağ üst köşeye açıklama ekliyoruz\n",
        "\n",
        "    plt.show()  # Grafikleri ekrana getiriyoruz\n",
        "\n",
        "# Eğitimi bitirmiş modelin test veri seti üzerindeki doğruluk ve kayıp değerlerini gösteren fonksiyon\n",
        "# Test seti üzerindeki model performansını değerlendirme\n",
        "def evaluate_model_on_test_set(cnn, test_set):\n",
        "    # Test setini değerlendirin\n",
        "    loss, accuracy = cnn.evaluate(test_set, verbose=False)\n",
        "    print(f\"Test Loss: {loss}\")\n",
        "    print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "# Test seti üzerindeki tahminleri gösterme\n",
        "def predict_and_evaluate(cnn, test_set):\n",
        "    # Test setindeki tahminleri alın\n",
        "    y_pred = cnn.predict(test_set)\n",
        "    # İlk 3 tahmini yazdırın\n",
        "    print(f\"First 3 predictions: {y_pred[:3]}\") \n",
        "\n",
        "\n",
        "# Şimdi bu fonksiyonları eğitim sonrası kullanım senaryosuna dahil ediyoruz\n",
        "plot_training_history(history)\n",
        "\n",
        "# Test seti üzerindeki model performansını değerlendiriyoruz\n",
        "evaluate_model_on_test_set(cnn, test_set)\n",
        "\n",
        "# Modelin test seti üzerindeki tahminlerine bakıyoruz \n",
        "predict_and_evaluate(cnn, test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 5 - Prediction TAHMİN AŞAMASI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsSiWEJY1BPB"
      },
      "outputs": [],
      "source": [
        "# BİZİM TERCİH ETTİĞİMİZ YÖNTEM \n",
        "# Opencv çünkü projelerin geliştirilebilir olmasını istiyoruz. Opencv kodlarına eklemeler yaparken Görüntülerinizi istediğiniz gibi özelleştirmek için daha fazla kontrol sağlar.\n",
        "import cv2\n",
        "import numpy as np \n",
        "image = cv2.imread('path/to/image.jpg') # Fotonun yolu \n",
        "image = cv2.resize(image, (128, 128))  # target_size işlemi\n",
        "image = image.astype('float32') / 255.0  # Normalizasyon \n",
        "image = np.expand_dims(image, axis=0)  # Boyutu 4 boyutlu yapmak (Detayı yöntem 2 de var.) \n",
        "predictions = cnn.predict(image)\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "class_labels = {0: 'Cat', 1: 'Dog'}  # Sınıf etiketlerini tanımla \n",
        "result = class_labels[predicted_class[0]]\n",
        "print(f'Tahmin Edilen Sınıf: {result}')\n",
        "\n",
        "# Sonuçları Görselleştirme (İsteğe Bağlı)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(cv2.cvtColor(cv2.imread('path/to/image.jpg'), cv2.COLOR_BGR2RGB))\n",
        "plt.title(f'Tahmin: {result}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODELİ KAYDET "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn.save('modelim1.keras')  # Modeli .keras formatında kaydeder. [ eskiden .h5 formatında kaydedermiş. ]\n",
        "#cnn = load_model('modelim.keras')  # Bir sonraki kullanım için kaydedilen modeli yükler."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EMefrVPCg-60",
        "oxQxCBWyoGPE",
        "MvE-heJNo3GG",
        "mrCMmGw9pHys",
        "u5YJj_XMl5LF",
        "tf87FpvxmNOJ",
        "xaTOgD8rm4mU",
        "tmiEuvTunKfk",
        "dAoSECOm203v",
        "yTldFvbX28Na",
        "D6XkI90snSDl",
        "U3PZasO0006Z"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
